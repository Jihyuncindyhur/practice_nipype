{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Output**\n",
    "\n",
    "Similarly important to data input is data oupt. Using a data output module allows you `to restructure and rename computed output` and `to spatially differentiate relevant output files from the temporary computed intermediate files in the working directory`. Nipype provides the following modules to handle data stream output:\n",
    "\n",
    "    DataSink\n",
    "    JSONFileSink\n",
    "    MySQLSink\n",
    "    SQLiteSink\n",
    "    XNATSink\n",
    "\n",
    "This tutorial covers only `DataSink`. For the rest, see the section interfaces.io on the official homepage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **DataSink**\n",
    "\n",
    "A workflow working directory is like a **cache(= 은닉처)**. It contains not only the outputs of various processing stages, it also contains various extraneous info such as execution reports, hashfiles determining the input state of processes. All of this is embedded in a hierarchical structure that reflects the iterables that have been used in the workflow. This makes navigating the working directory a not so pleasant experience. \n",
    "\n",
    "And typically the user is interested in preserving only a small percentage of these outputs. The `DataSink` interface can be used to extract components from this `cache` and store it at a different location.\n",
    "\n",
    "Unlike other interfaces, a DataSink's inputs are defined and created by using **the workflow connect statement**. Currently disconnecting an input from the DataSink does not remove that connection port.\n",
    "\n",
    "The following code segment defines the 'DataSink' node and sets the `base_directory` in which all outputs will be stored. The `container` input creates a subdirectory within the `base_directory`. If you are iterating a workflow over subjects, it may be useful to save it within a floder with the subject id."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "datasink = pe.Node(nio.DataSink(), name='sinker')\n",
    "datasink.inputs.base_directory = '/path/to/output'\n",
    "workflow.connect(inputnode, 'subject_id', datasink, 'container')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to save the realigned files and the realignment parameters to the same place, the most intuitive option would be:\n",
    "\n",
    "```python\n",
    "workflow.connect(realigner, 'realigned_files', datasink, 'motion')\n",
    "workflow.connect(realigner, 'realignment_parameters', datasink, 'motion')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this will not work as only one connection is allowed per input port. So we need to create a second port. We can store the files in a separate folder.\n",
    "\n",
    "```python\n",
    "workflow.connect(realigner, 'realigned_files', datasink, 'motion')\n",
    "workflow.connect(realigner, 'realignment_parameters', datasink, 'motion.par')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The period(.) indicates that a subfolder called par should be created. But if we wanted to store it in the same folder as the realigned files, we would use the .@ syntax. The @ tells the DataSink interface to not create the subfolder. This will allow us to create different named input ports for DataSink and allow the user to store the files in the same folder.\n",
    "\n",
    "```python\n",
    "workflow.connect(realigner, 'realigned_fiels', datasink, 'motion')\n",
    "workflow.connect(realigner, 'realignment_parameters', datasink, 'motion.@par')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The syntax for the input port of DataSink takes the following form:\n",
    "\n",
    "```python\n",
    "string[[.@]]string[[.[@]]string] ...]\n",
    "where parts between paired [] are optional.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **MapNode**\n",
    "\n",
    "In order to use DataSink inside a MapNode, its inputs have to be defined inside the constructor using the `infields` keyword arg.\n",
    "\n",
    "### **Parameterization**\n",
    "\n",
    "One can run a workflow iterating over various inputs using the iterables attribute of nodes. This means that a given workflow can have multiple outputs depending on how many iterables are there. Iterables create working directory subfolders such as `_iterable_name_value`. \n",
    "\n",
    "The `parameterization` input parameter controls whether the data stored using DataSink is in a folder structure that contains this iterable info or not.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Substitutions**\n",
    "\n",
    "The `substitutions and regexp_substitutions` inputs allow users to modify the output destination path and name of a file. Substitutions are a list of 2-tuples and are carried out in the order in which they were entered. Assuming that the output path of a file is:\n",
    "\n",
    "    /root/container/_variable_1/file_subject_realigned.nii\n",
    "    \n",
    "We can use subsitutions to clean up the output path.\n",
    "\n",
    "```python\n",
    "datasink.inputs.substitutions = [('_variable', 'variable'),\n",
    "                                 ('file_subject_', '')]\n",
    "```\n",
    "\n",
    "This will rewrite the file as:\n",
    "\n",
    "    /root/container/variable_1/realigned.nii"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Preparation**\n",
    "\n",
    "Before we can use DataSink, we first need to run a workflow. \n",
    "\n",
    "Let's create a very short preprocessing workflow that realigns and smooths one functional image of one subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype import SelectFiles, Node\n",
    "\n",
    "templates = {'func' : '{subject}/func/{subject}_task-calorieimage_run-03_bold.nii.gz'}\n",
    "\n",
    "sf = Node(SelectFiles(templates), name=\"selectfiles\")\n",
    "sf.inputs.base_directory = '/data/ds001534/'\n",
    "sf.inputs.subject = 'sub-01'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, let's create the motion correction and smoothing node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces.fsl import MCFLIRT, IsotropicSmooth\n",
    "\n",
    "mcflirt = Node(MCFLIRT(mean_vol=True,\n",
    "                       save_plots=True), #save_plots?\n",
    "               name='mcflirt')\n",
    "\n",
    "smooth = Node(IsotropicSmooth(fwhm=4),\n",
    "              name='smooth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third, let's create the workflow that will contain those three nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190129-08:50:41,391 nipype.workflow INFO:\n",
      "\t Workflow preprocWF settings: ['check', 'execution', 'logging', 'monitoring']\n",
      "190129-08:50:41,415 nipype.workflow INFO:\n",
      "\t Running serially.\n",
      "190129-08:50:41,417 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"preprocWF.selectfiles\" in \"/output/working_dir/preprocWF/selectfiles\".\n",
      "190129-08:50:41,432 nipype.workflow INFO:\n",
      "\t [Node] Running \"selectfiles\" (\"nipype.interfaces.io.SelectFiles\")\n",
      "190129-08:50:41,477 nipype.workflow INFO:\n",
      "\t [Node] Finished \"preprocWF.selectfiles\".\n",
      "190129-08:50:41,480 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"preprocWF.mcflirt\" in \"/output/working_dir/preprocWF/mcflirt\".\n",
      "190129-08:50:41,504 nipype.workflow INFO:\n",
      "\t [Node] Running \"mcflirt\" (\"nipype.interfaces.fsl.preprocess.MCFLIRT\"), a CommandLine Interface with command:\n",
      "mcflirt -in /data/ds001534/sub-01/func/sub-01_task-calorieimage_run-03_bold.nii.gz -meanvol -out /output/working_dir/preprocWF/mcflirt/sub-01_task-calorieimage_run-03_bold_mcf.nii.gz -plots\n",
      "190129-08:51:29,796 nipype.workflow INFO:\n",
      "\t [Node] Finished \"preprocWF.mcflirt\".\n",
      "190129-08:51:29,797 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"preprocWF.smooth\" in \"/output/working_dir/preprocWF/smooth\".\n",
      "190129-08:51:29,822 nipype.workflow INFO:\n",
      "\t [Node] Running \"smooth\" (\"nipype.interfaces.fsl.maths.IsotropicSmooth\"), a CommandLine Interface with command:\n",
      "fslmaths /output/working_dir/preprocWF/mcflirt/sub-01_task-calorieimage_run-03_bold_mcf.nii.gz -s 1.69864 /output/working_dir/preprocWF/smooth/sub-01_task-calorieimage_run-03_bold_mcf_smooth.nii.gz\n",
      "190129-08:51:43,72 nipype.workflow INFO:\n",
      "\t [Node] Finished \"preprocWF.smooth\".\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<networkx.classes.digraph.DiGraph at 0x7f6ab97c2dd8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nipype import Workflow\n",
    "from os.path import abspath\n",
    "\n",
    "wf = Workflow(name=\"preprocWF\")\n",
    "wf.base_dir = '/output/working_dir'\n",
    "\n",
    "wf.connect([(sf, mcflirt, [(\"func\", \"in_file\")]),\n",
    "            (mcflirt, smooth, [(\"out_file\", \"in_file\")])])\n",
    "\n",
    "wf.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the execution of the workflow we have all the data hidden in the working directory 'working_dir'. Let's take a closer look at the content of this folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/output/working_dir/preprocWF\n",
      "├── d3.js\n",
      "├── graph1.json\n",
      "├── graph.json\n",
      "├── index.html\n",
      "├── mcflirt\n",
      "│   ├── _0xc369ae8fe58d7133de9c6eed6eac1ffe.json\n",
      "│   ├── command.txt\n",
      "│   ├── _inputs.pklz\n",
      "│   ├── _node.pklz\n",
      "│   ├── _report\n",
      "│   │   └── report.rst\n",
      "│   ├── result_mcflirt.pklz\n",
      "│   └── sub-01_task-calorieimage_run-03_bold_mcf.nii.gz\n",
      "├── selectfiles\n",
      "│   ├── _0x76930eb00c96b2ea8c0523c89ee5bc69.json\n",
      "│   ├── _inputs.pklz\n",
      "│   ├── _node.pklz\n",
      "│   ├── _report\n",
      "│   │   └── report.rst\n",
      "│   └── result_selectfiles.pklz\n",
      "└── smooth\n",
      "    ├── _0x0ad8446e4bc6fcfcbf492fe07dedc570.json\n",
      "    ├── command.txt\n",
      "    ├── _inputs.pklz\n",
      "    ├── _node.pklz\n",
      "    ├── _report\n",
      "    │   └── report.rst\n",
      "    ├── result_smooth.pklz\n",
      "    └── sub-01_task-calorieimage_run-03_bold_mcf_smooth.nii.gz\n",
      "\n",
      "6 directories, 23 files\n"
     ]
    }
   ],
   "source": [
    "! tree /output/working_dir/preprocWF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **How to use `DataSink`**\n",
    "\n",
    "`DataSink` is Nipype's standard output module to **restructure your output files.** It allows you to relocate and rename files that you deem relevant. \n",
    "\n",
    "Let's try to keep the smoothed functional images as well as the motion correction parameters (what is the file that stores the motion correction parameters?). To do this, we first need to create the `DataSink` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Duplicate node name \"sinker\" found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-f39802ac0494>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m wf.connect([(smooth, sinker, [('out_file', 'in_file')]),\n\u001b[1;32m     11\u001b[0m             (mcflirt, sinker, [('mean_img', 'mean_img'),\n\u001b[0;32m---> 12\u001b[0;31m                                ('par_file', 'par_file')])\n\u001b[0m\u001b[1;32m     13\u001b[0m            ])\n\u001b[1;32m     14\u001b[0m \u001b[0mwf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda-latest/envs/neuro/lib/python3.6/site-packages/nipype/pipeline/engine/workflows.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m                 \u001b[0mnewnodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewnodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewnodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnewnodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hierarchy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda-latest/envs/neuro/lib/python3.6/site-packages/nipype/pipeline/engine/workflows.py\u001b[0m in \u001b[0;36m_check_nodes\u001b[0;34m(self, nodes)\u001b[0m\n\u001b[1;32m    725\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mthis_node_lineage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hierarchy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m                         raise IOError(\n\u001b[0;32m--> 727\u001b[0;31m                             'Duplicate node name \"%s\" found.' % node.name)\n\u001b[0m\u001b[1;32m    728\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m                 \u001b[0mnode_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Duplicate node name \"sinker\" found."
     ]
    }
   ],
   "source": [
    "from nipype.interfaces.io import DataSink\n",
    "\n",
    "# Create DataSink object\n",
    "sinker = Node(DataSink(), name='sinker')\n",
    "\n",
    "# Name of the output folder\n",
    "sinker.inputs.base_directory = '/output/working_dir/preprocWR_output'\n",
    "\n",
    "# Connect DataSink with the relevant nodes\n",
    "wf.connect([(smooth, sinker, [('out_file', 'in_file')]),\n",
    "            (mcflirt, sinker, [('mean_img', 'mean_img'),\n",
    "                               ('par_file', 'par_file')])\n",
    "           ])\n",
    "wf.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/output/working_dir/preprocWR_output\n",
      "├── in_file\n",
      "│   └── sub-01_task-calorieimage_run-03_bold_mcf_smooth.nii.gz\n",
      "├── mean_img\n",
      "│   └── sub-01_task-calorieimage_run-03_bold_mcf.nii.gz_mean_reg.nii.gz\n",
      "└── par_file\n",
      "    └── sub-01_task-calorieimage_run-03_bold_mcf.nii.gz.par\n",
      "\n",
      "3 directories, 3 files\n"
     ]
    }
   ],
   "source": [
    "! tree /output/working_dir/preprocWR_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
